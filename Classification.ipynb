{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Sample Data Framework - Policy Database.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Policy Title','...Page #', '...Page #.1', 'Link', 'Notes','Summary','Purpose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only use the most recent year\n",
    "df['Year'].iloc[48] = '2018'\n",
    "df['Year'].iloc[49] = '2017'\n",
    "df['Year'].iloc[79] = '2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df['Key Words'].iloc[i] = df['Key Words'].iloc[i].split(',')\n",
    "    df['Year'].iloc[i] = int(df['Year'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_incentives = ['Diplomatic', 'Financial - grants', 'Financial - subsidies',\n",
    "       'Financial - subsidies,Financial - grants',\n",
    "       'Financial - subsidies,Legal', 'Financial - tax break',\n",
    "       'Financial - trade', 'Legal', 'None', 'Political']\n",
    "primary_disincentives = ['Financial - fines', 'Financial - fines,Legal',\n",
    "       'Financial - fines,Legal,Imprisonment and Fines',\n",
    "       'Financial - fines,Legal,Political',\n",
    "       'Financial - fines,Political,Procedures/Guidelines',\n",
    "       'Imprisonment and Fines', 'Legal', 'None', 'Political',\n",
    "       'Procedures/Guidelines']\n",
    "motivations = ['Agricultural Development', 'Climate Change Action', 'Conservation',\n",
    "       'Define ecologic-economical zoning of legal Amazon',\n",
    "       'Establish Amazon Fund',\n",
    "       'Establishes Forest Service and promotes forest management principles',\n",
    "       'Establishes system of Nature Conservation Units',\n",
    "       'Fund research on GHG mitigation and promote REDD+ projects',\n",
    "       'International Agreement/Conference',\n",
    "       'Mitigate and address the environmental impacts of climate change',\n",
    "       'None', 'Previous Supreme Court Ruling',\n",
    "       'Promote conservation activites ']\n",
    "land_use = ['Farmed land', 'Forest land', 'Forest land,Farmed land',\n",
    "       'Forest land,Farmed land,Protective land and buffers',\n",
    "       'Forest land,Protective land and buffers', 'None',\n",
    "       'Protective land and buffers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Country',\n",
    "            'Jurisdiction',\n",
    "            'Bottom-up:\\nCommunity Engagement',\n",
    "           'Bottom-up:\\nIndigenous Rights',\n",
    "           'Biome-Specific',\n",
    "           'Hectare Quantity',\n",
    "           'Motivation',\n",
    "           'Primary Incentive...',\n",
    "           'Primary Disincentive...',\n",
    "           'ROAM+: Land Use',\n",
    "           'ROAM+: Category',\n",
    "           'ROAM+: Intervention',\n",
    "           'Enacted By Law',\n",
    "           'Enacted By Exec.', \n",
    "           'Voluntary/NDC', \n",
    "           'Passed', \n",
    "           'Active',\n",
    "           'Executing Ministry', \n",
    "           'Enforcement Mechanism']\n",
    "\n",
    "for i, col in enumerate(cat_cols):\n",
    "    df[col] = df[col].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = ['afforestation','agriculture','animal welfare','artificial regeneration','biodiversity',\n",
    "             'biological resources','biome','board','clean','coconut','conservation','control','database',\n",
    "             'enforcement','environment','farm','financing','forest','forest protection','funding','fundraising',\n",
    "             'land ','land use','landholder','law','measuring','mobilization','monitor','natural resources',\n",
    "             'oversight','plant breeders','plants','pollution','preservation','produce','protection','qualification',\n",
    "             'quality','registry','regulation','reporting','reserve','resource','restriction','results-driven',\n",
    "             'rural','safeguard','species' ,'support','sustainable','technical submission','threatened species',\n",
    "             'variety','verification','wastewater','water','watershed','wild life']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in key_words:\n",
    "    df[word] = [int(word in df['Key Words'].iloc[i]) for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Key Words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Country', 'Jurisdiction', 'Enacted By Law', 'Enacted By Exec.',\n",
       "       'Voluntary/NDC', 'Passed', 'Active', 'Executing Ministry',\n",
       "       'Enforcement Mechanism', 'Motivation', 'Primary Incentive...',\n",
       "       'Primary Disincentive...', 'Bottom-up:\\nCommunity Engagement',\n",
       "       'Bottom-up:\\nIndigenous Rights', 'Biome-Specific', 'ROAM+: Land Use',\n",
       "       'ROAM+: Category', 'ROAM+: Intervention', 'Hectare Quantity',\n",
       "       'afforestation', 'agriculture', 'animal welfare',\n",
       "       'artificial regeneration', 'biodiversity', 'biological resources',\n",
       "       'biome', 'board', 'clean', 'coconut', 'conservation', 'control',\n",
       "       'database', 'enforcement', 'environment', 'farm', 'financing', 'forest',\n",
       "       'forest protection', 'funding', 'fundraising', 'land ', 'land use',\n",
       "       'landholder', 'law', 'measuring', 'mobilization', 'monitor',\n",
       "       'natural resources', 'oversight', 'plant breeders', 'plants',\n",
       "       'pollution', 'preservation', 'produce', 'protection', 'qualification',\n",
       "       'quality', 'registry', 'regulation', 'reporting', 'reserve', 'resource',\n",
       "       'restriction', 'results-driven', 'rural', 'safeguard', 'species',\n",
       "       'support', 'sustainable', 'technical submission', 'threatened species',\n",
       "       'variety', 'verification', 'wastewater', 'water', 'watershed',\n",
       "       'wild life'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Primary Incentive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop(columns=['Motivation', 'Primary Incentive...',\n",
    "#        'Primary Disincentive...', 'Bottom-up:\\nCommunity Engagement',\n",
    "#        'Bottom-up:\\nIndigenous Rights', 'Biome-Specific', 'ROAM+: Land Use',\n",
    "#        'ROAM+: Category', 'ROAM+: Intervention', 'Hectare Quantity',])\n",
    "X = df[key_words]\n",
    "y = df['Primary Incentive...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35714285714285715"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, svm.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/catharinewu/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/Users/catharinewu/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, lda.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlc = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "mlc.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35714285714285715"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, mlc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, dt.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21428571428571427"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, neigh.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Random Forest to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_me = np.array([0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 1,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Legal'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_incentives[rf.predict(try_me.reshape(1,-1))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
